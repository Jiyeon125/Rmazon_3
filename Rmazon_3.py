import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv('cleaned_w_productName.csv')
    df = df.dropna(subset=['about_product', 'discounted_price', 'rating', 'rating_count', 'discount_percentage'])
    return df

df = load_data()

st.title("ğŸ“Š ìœ ì‚¬ ì œí’ˆ ì¶”ì²œ ë° ë¹„êµ ë„êµ¬")

# ğŸ“ íŒë§¤ì ì…ë ¥ ë°›ê¸°
product_desc = st.text_area("ì œí’ˆ ì„¤ëª… ì…ë ¥", value="wireless bluetooth earbuds with noise cancelling and long battery life")
price = st.number_input("í• ì¸ê°€", min_value=0, value=2499)
rating = st.slider("í‰ì ", 0.0, 5.0, 4.2)
review_count = st.number_input("ë¦¬ë·° ìˆ˜", min_value=0, value=150)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)

if st.button("ìœ ì‚¬ ì œí’ˆ ì¶”ì²œ"):
    # Step 1: TF-IDF
    tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
    tfidf_matrix = tfidf.fit_transform(df['about_product'])
    query_vec = tfidf.transform([product_desc])
    cos_sim = cosine_similarity(query_vec, tfidf_matrix)

    top_indices = cos_sim[0].argsort()[::-1][:50]
    candidate_df = df.iloc[top_indices].copy()

    # Step 2: KMeans
    num_cols = ['discounted_price', 'rating', 'rating_count', 'discount_percentage']
    X = candidate_df[num_cols]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    kmeans = KMeans(n_clusters=5, random_state=0)
    candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

    input_features = [[price, rating, review_count, discount_pct]]
    input_scaled = scaler.transform(input_features)
    input_cluster = kmeans.predict(input_scaled)[0]

    cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
    member_scaled = scaler.transform(cluster_members[num_cols])

    dists = euclidean_distances(input_scaled, member_scaled)[0]
    cluster_members = cluster_members.copy()
    cluster_members['distance'] = dists

    top_matches = cluster_members.sort_values('distance').head(3)

    st.subheader("ğŸ“‹ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")
    st.dataframe(top_matches[['product_name', 'discounted_price', 'rating', 'rating_count', 'discount_percentage', 'distance']])
