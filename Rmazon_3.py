import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv('cleaned_w_productName.csv')
    df = df.dropna(subset=['about_product', 'discounted_price', 'rating', 'rating_count', 'discount_percentage'])
    return df

df = load_data()

st.title("ğŸ“Š ì‹œì¥ ë‚´ ì œí’ˆ ë¹„êµ ë„êµ¬")

# ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ì„ íƒ
category_list = df['category'].dropna().unique().tolist()
selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", sorted(category_list))

# ğŸ“ íŒë§¤ì ì…ë ¥ ë°›ê¸°
product_desc = st.text_area("ì œí’ˆ ì„¤ëª… ì…ë ¥", value="wireless bluetooth earbuds with noise cancelling and long battery life")
price = st.number_input("í• ì¸ê°€(ë£¨í”¼ ê¸°ì¤€)", min_value=0, value=2499)
rating = st.slider("í‰ì ", 0.0, 5.0, 4.2)
review_count = st.number_input("ë¦¬ë·° ìˆ˜", min_value=0, value=150)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)

if st.button("ìœ ì‚¬í•œ ì œí’ˆ"):
    # âœ… Step 1: ì¹´í…Œê³ ë¦¬ í•„í„°ë§
    df_filtered = df[df['category'] == selected_category]

    # âœ… Step 2: TF-IDFë¡œ ì œí’ˆ ì„¤ëª… ê¸°ë°˜ í›„ë³´êµ° ì¶”ì¶œ
    tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
    tfidf_matrix = tfidf.fit_transform(df_filtered['about_product'])
    query_vec = tfidf.transform([product_desc])
    cos_sim = cosine_similarity(query_vec, tfidf_matrix)

    top_indices = cos_sim[0].argsort()[::-1][:50]
    candidate_df = df_filtered.iloc[top_indices].copy()

    # âœ… Step 3: ìˆ˜ì¹˜í˜• ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
    num_cols = ['discounted_price', 'rating', 'rating_count', 'discount_percentage']
    X = candidate_df[num_cols]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    kmeans = KMeans(n_clusters=5, random_state=0)
    candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

    input_features = [[price, rating, review_count, discount_pct]]
    input_scaled = scaler.transform(input_features)
    input_cluster = kmeans.predict(input_scaled)[0]

    # âœ… Step 4: ê°™ì€ í´ëŸ¬ìŠ¤í„°ì—ì„œ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ ì œí’ˆ Top 3 ì¶”ì¶œ
    cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
    member_scaled = scaler.transform(cluster_members[num_cols])
    dists = euclidean_distances(input_scaled, member_scaled)[0]
    cluster_members = cluster_members.copy()
    cluster_members['distance'] = dists

    top_matches = cluster_members.sort_values('distance').head(3)

    # âœ… ê²°ê³¼ ì¶œë ¥
    st.subheader("ğŸ“‹ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")
    st.dataframe(top_matches[['product_name', 'discounted_price', 'rating', 'rating_count', 'discount_percentage', 'distance']])
