import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv('cleaned_w_productName.csv')
    df = df.dropna(subset=['about_product', 'discounted_price', 'rating', 'rating_count', 'discount_percentage'])
    return df

df = load_data()

st.title("ğŸ“Š ìœ ì‚¬ ì œí’ˆ ì¶”ì²œ ë° ë¹„êµ ë„êµ¬")

# ğŸ” ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ + ì„ íƒ
category_list = sorted(df['category'].dropna().unique().tolist())
typed = st.text_input("ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰", "")

filtered_categories = [cat for cat in category_list if typed.lower() in cat.lower()]
selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ (ìë™ì™„ì„±)", filtered_categories) if filtered_categories else None

# ğŸ“ íŒë§¤ì ì…ë ¥ ë°›ê¸°
product_desc = st.text_area("ì œí’ˆ ì„¤ëª… ì…ë ¥", value="wireless bluetooth earbuds with noise cancelling and long battery life")
price = st.number_input("í• ì¸ê°€", min_value=0, value=2499)
rating = st.slider("í‰ì ", 0.0, 5.0, 4.2)
review_count = st.number_input("ë¦¬ë·° ìˆ˜", min_value=0, value=150)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)

if st.button("ìœ ì‚¬ ì œí’ˆ ì¶”ì²œ"):
    if selected_category is None:
        st.warning("ì¹´í…Œê³ ë¦¬ë¥¼ ë¨¼ì € ê²€ìƒ‰ í›„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        # âœ… Step 1: ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        df_filtered = df[df['category'] == selected_category]

        # âœ… Step 2: TF-IDF + ìœ ì‚¬ë„ ê³„ì‚°
        tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
        tfidf_matrix = tfidf.fit_transform(df_filtered['about_product'])
        query_vec = tfidf.transform([product_desc])
        cos_sim = cosine_similarity(query_vec, tfidf_matrix)

        top_indices = cos_sim[0].argsort()[::-1][:50]
        candidate_df = df_filtered.iloc[top_indices].copy()

        # âœ… Step 3: ìˆ˜ì¹˜í˜• í´ëŸ¬ìŠ¤í„°ë§
        num_cols = ['discounted_price', 'rating', 'rating_count', 'discount_percentage']
        X = candidate_df[num_cols]
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        kmeans = KMeans(n_clusters=5, random_state=0)
        candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

        input_features = [[price, rating, review_count, discount_pct]]
        input_scaled = scaler.transform(input_features)
        input_cluster = kmeans.predict(input_scaled)[0]

        cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
        member_scaled = scaler.transform(cluster_members[num_cols])

        dists = euclidean_distances(input_scaled, member_scaled)[0]
        cluster_members = cluster_members.copy()
        cluster_members['distance'] = dists

        top_matches = cluster_members.sort_values('distance').head(3)

        # âœ… ì¶œë ¥
        st.subheader("ğŸ“‹ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")
        st.dataframe(top_matches[['product_name', 'discounted_price', 'rating', 'rating_count', 'discount_percentage', 'distance']])
