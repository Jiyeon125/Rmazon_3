import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv('cleaned_amazon_0519.csv')  # âœ… íŒŒì¼ëª… ë°˜ì˜
    df = df.dropna(subset=['about_product', 'discounted_price', 'rating', 'rating_count', 'discount_percentage'])
    return df

df = load_data()

# ğŸ§± ì•± ì œëª©
st.title("ğŸ“Š ì‹œì¥ ë‚´ ìœ ì‚¬ ì œí’ˆ íƒìƒ‰ê¸°")

# ğŸ” ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ + ìë™ì™„ì„± ì„ íƒ
category_list = sorted(df['category'].dropna().unique().tolist())
typed = st.text_input("ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰", "")
filtered_categories = [cat for cat in category_list if typed.lower() in cat.lower()]
selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ (ìë™ì™„ì„±)", filtered_categories) if filtered_categories else None

# ğŸ“ ì…ë ¥ê°’
product_desc = st.text_area("ì œí’ˆ ì„¤ëª… ì…ë ¥", value="wireless bluetooth earbuds with noise cancelling and long battery life")
price = st.number_input("í• ì¸ê°€", min_value=0, value=2499)
rating = st.slider("í‰ì ", 0.0, 5.0, 4.2)
review_count = st.number_input("ë¦¬ë·° ìˆ˜", min_value=0, value=150)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)

# â–¶ï¸ ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰
if st.button("ìœ ì‚¬ ì œí’ˆ íƒìƒ‰í•˜ê¸°"):
    if selected_category is None:
        st.warning("ì¹´í…Œê³ ë¦¬ë¥¼ ë¨¼ì € ê²€ìƒ‰ í›„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        df_filtered = df[df['category'] == selected_category]

        if len(df_filtered) < 5:
            st.error("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ ë‚´ ì œí’ˆ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        else:
            # TF-IDF ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚°
            tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
            tfidf_matrix = tfidf.fit_transform(df_filtered['about_product'])
            query_vec = tfidf.transform([product_desc])
            cos_sim = cosine_similarity(query_vec, tfidf_matrix)

            top_n = min(50, len(df_filtered))
            top_indices = cos_sim[0].argsort()[::-1][:top_n]
            candidate_df = df_filtered.iloc[top_indices].copy()

            if len(candidate_df) < 3:
                st.error("ìœ ì‚¬í•œ ì œí’ˆì´ 3ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. ì„¤ëª…ì„ ë‹¤ì‹œ ì…ë ¥í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ ì£¼ì„¸ìš”.")
            else:
                # ğŸ¯ ìœ ì‚¬ë„ ì§„ë‹¨
                mean_sim = cos_sim[0][top_indices].mean()
                max_sim = cos_sim[0][top_indices].max()

                similarity_warnings = []
                if mean_sim < 0.05:
                    similarity_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ì´ ë‹¤ë¥¸ ì œí’ˆë“¤ê³¼ ì „ë°˜ì ìœ¼ë¡œ í¬ê²Œ ë‹¤ë¦…ë‹ˆë‹¤. ìœ ì‚¬ ì œí’ˆ ëª©ë¡ì˜ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (í‰ê·  ìœ ì‚¬ë„ ë‚®ìŒ)\nê¶Œì¥: ì„¤ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ë³´ì„¸ìš”.")
                if max_sim < 0.1:
                    similarity_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ê³¼ ë§¤ìš° ìœ ì‚¬í•œ ì œí’ˆì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. ìœ ì‚¬ ì œí’ˆ ëª©ë¡ì˜ ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ìµœê³  ìœ ì‚¬ë„ ë‚®ìŒ)")

                # í´ëŸ¬ìŠ¤í„°ë§ ì¤€ë¹„
                num_cols = ['discounted_price', 'rating', 'rating_count', 'discount_percentage']
                X = candidate_df[num_cols]
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                k = min(5, len(candidate_df))
                kmeans = KMeans(n_clusters=k, random_state=0)
                candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

                input_features = [[price, rating, review_count, discount_pct]]
                input_scaled = scaler.transform(input_features)
                input_cluster = kmeans.predict(input_scaled)[0]

                cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
                member_scaled = scaler.transform(cluster_members[num_cols])
                dists = euclidean_distances(input_scaled, member_scaled)[0]
                cluster_members = cluster_members.copy()
                cluster_members['distance'] = dists

                top_matches = cluster_members.sort_values('distance').head(3)

                # âœ… ê²°ê³¼ ì¶œë ¥
                st.subheader("ğŸ“‹ ê°€ì¥ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")
                st.dataframe(top_matches[['product_name', 'discounted_price', 'rating', 'rating_count', 'discount_percentage', 'distance']])
                st.caption("ğŸ“Œ Distance ê°’ì´ ì‘ì„ìˆ˜ë¡ ì…ë ¥ ì œí’ˆê³¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì œí’ˆì…ë‹ˆë‹¤.")

                # âš ï¸ ìœ ì‚¬ë„ ì§„ë‹¨ ê²°ê³¼ ë©”ì‹œì§€ ì¶œë ¥
                if similarity_warnings:
                    st.warning("\n\n".join(similarity_warnings))
