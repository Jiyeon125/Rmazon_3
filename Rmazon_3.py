import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from transformers import T5Tokenizer, T5ForConditionalGeneration

# ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data
def load_data():
    df = pd.read_csv('cleaned_amazon_0519.csv')
    df = df.dropna(subset=['about_product', 'discounted_price', 'discount_percentage'])
    return df

df = load_data()

# ğŸ§  T5 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_resource
def load_t5_model():
    tokenizer = T5Tokenizer.from_pretrained("t5-base")
    model = T5ForConditionalGeneration.from_pretrained("t5-base")
    return tokenizer, model

tokenizer, t5_model = load_t5_model()

def t5_summarize(text, max_length=100):
    input_text = "summarize: " + text.strip().replace("\n", " ")
    inputs = tokenizer.encode(input_text, return_tensors="pt", truncation=True)
    outputs = t5_model.generate(inputs, max_length=max_length, num_beams=4, early_stopping=True)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ğŸ’¬ í™”ë©´ êµ¬ì„±
st.title("ğŸ§­ ì˜ˆë¹„ íŒë§¤ìë¥¼ ìœ„í•œ ì‹œì¥ ë‚´ ìœ ì‚¬ ìƒí’ˆ íƒìƒ‰ê¸°")

category_list = sorted(df['category'].dropna().unique().tolist())
typed = st.text_input("ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰", "")
filtered_categories = [cat for cat in category_list if typed.lower() in cat.lower()]
selected_category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", filtered_categories) if filtered_categories else None

product_desc = st.text_area("ìƒí’ˆ ì„¤ëª… ì…ë ¥", placeholder="ì˜ˆì‹œ: Outdoor camping gear with solar panel")
actual_price = st.number_input("ì •ê°€ (â‚¹)", min_value=0, value=3000)
discount_pct = st.slider("í• ì¸ìœ¨ (%)", 0, 100, 20)
discounted_price = int(actual_price * (1 - discount_pct / 100))
st.markdown(f"**í• ì¸ê°€ (ìë™ ê³„ì‚°): â‚¹{discounted_price}**")

# â–¶ï¸ ì‹¤í–‰
if st.button("ì‹œì¥ ë‚´ ìœ ì‚¬ ìƒí’ˆ íƒìƒ‰í•˜ê¸°"):
    if selected_category is None:
        st.warning("ì¹´í…Œê³ ë¦¬ë¥¼ ë¨¼ì € ê²€ìƒ‰ í›„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        df_filtered = df[df['category'] == selected_category]

        if len(df_filtered) < 5:
            st.error("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ ë‚´ ì œí’ˆ ìˆ˜ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤.")
        else:
            tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
            tfidf_matrix = tfidf.fit_transform(df_filtered['about_product'])
            query_vec = tfidf.transform([product_desc])
            cos_sim = cosine_similarity(query_vec, tfidf_matrix)

            top_n = min(50, len(df_filtered))
            top_indices = cos_sim[0].argsort()[::-1][:top_n]
            candidate_df = df_filtered.iloc[top_indices].copy()

            if len(candidate_df) < 3:
                st.error("ìœ ì‚¬í•œ ì œí’ˆì´ 3ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤.")
            else:
                mean_sim = cos_sim[0][top_indices].mean()
                max_sim = cos_sim[0][top_indices].max()

                similarity_warnings = []
                if mean_sim < 0.05:
                    similarity_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ì´ ë‹¤ë¥¸ ì œí’ˆë“¤ê³¼ ì „ë°˜ì ìœ¼ë¡œ í¬ê²Œ ë‹¤ë¦…ë‹ˆë‹¤. (í‰ê·  ìœ ì‚¬ë„ ë‚®ìŒ)\nê¶Œì¥: ì„¤ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ ë³´ì„¸ìš”.")
                if max_sim < 0.1:
                    similarity_warnings.append("âš ï¸ ì…ë ¥í•œ ì„¤ëª…ê³¼ ë§¤ìš° ìœ ì‚¬í•œ ì œí’ˆì´ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤. (ìµœê³  ìœ ì‚¬ë„ ë‚®ìŒ)")

                # í´ëŸ¬ìŠ¤í„°ë§
                num_cols = ['actual_price', 'discount_percentage']
                candidate_df['actual_price'] = candidate_df['discounted_price'] / (1 - candidate_df['discount_percentage'] / 100)
                X = candidate_df[['actual_price', 'discount_percentage']]
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)

                k = min(5, len(candidate_df))
                kmeans = KMeans(n_clusters=k, random_state=0)
                candidate_df['cluster'] = kmeans.fit_predict(X_scaled)

                input_features = [[actual_price, discount_pct]]
                input_scaled = scaler.transform(input_features)
                input_cluster = kmeans.predict(input_scaled)[0]

                cluster_members = candidate_df[candidate_df['cluster'] == input_cluster]
                member_scaled = scaler.transform(cluster_members[['actual_price', 'discount_percentage']])
                dists = euclidean_distances(input_scaled, member_scaled)[0]
                cluster_members = cluster_members.copy()
                cluster_members['distance'] = dists

                top_matches = cluster_members.sort_values('distance').head(3).reset_index(drop=True)

                # âš ï¸ ê²½ê³  ì¶œë ¥
                if similarity_warnings:
                    st.warning("\n\n".join(similarity_warnings))

                # ğŸ“‹ ê²°ê³¼ ì¶œë ¥
                st.subheader("ğŸ“‹ ìœ ì‚¬í•œ ìƒìœ„ 3ê°œ ì œí’ˆ")
                for i, row in top_matches.iterrows():
                    st.markdown(f"### {i+1}ìœ„. {row['product_name']}")
                    cols = st.columns([1, 3])
                    with cols[0]:
                        st.image(row['img_link'], width=120)
                    with cols[1]:
                        st.markdown(f"**Distance**: `{row['distance']:.4f}`")
                        st.markdown(f"`ì •ê°€`: â‚¹{int(row['actual_price'])} / `í• ì¸ìœ¨`: {int(row['discount_percentage'])}% / `í• ì¸ê°€`: â‚¹{int(row['discounted_price'])}")
                        st.markdown(f"`í‰ì `: {row.get('rating', 'N/A')} â­ / `ë¦¬ë·° ìˆ˜`: {row.get('rating_count', 'N/A')}")
                        # ğŸ§  ê°œë³„ ì œí’ˆ ë¦¬ë·° ìš”ì•½ ì¶”ê°€
                        summary_text = row.get("full_summary", "")
                        if pd.notna(summary_text) and summary_text.strip():
                            try:
                                with st.spinner("AIê°€ í•´ë‹¹ ì œí’ˆì˜ ë¦¬ë·° ìš”ì•½ ì¤‘..."):
                                    review_summary = t5_summarize(summary_text, max_length=50)
                                    st.markdown(f"ğŸ§  **AI ë¦¬ë·° ìš”ì•½:** {review_summary}")
                            except Exception as e:
                                st.markdown("ğŸ§  **AI ë¦¬ë·° ìš”ì•½:** (ìš”ì•½ ì‹¤íŒ¨)")
                                st.error(str(e))
                        else:
                            st.markdown("ğŸ§  **AI ë¦¬ë·° ìš”ì•½:** (ë¦¬ë·° ìš”ì•½ ì •ë³´ ì—†ìŒ)")


                # ğŸ§  AI ë¦¬ë·° ìš”ì•½
                if 'full_summary' in cluster_members.columns:
                    review_text = " ".join(top_matches['full_summary'].dropna().astype(str).tolist())
                    if review_text.strip():
                        with st.spinner("AIê°€ ë¦¬ë·° ìš”ì•½ ì¤‘ì…ë‹ˆë‹¤..."):
                            summary = t5_summarize(review_text, max_length=100)
                        st.subheader("ğŸ§  AI ë¦¬ë·° ìš”ì•½")
                        st.markdown(f"> {summary}")
